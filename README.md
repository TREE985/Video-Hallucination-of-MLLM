# Video-Hallucination-of-MLLM

This repository collects research papers related to hallucination in Multimodal Large Language Models (MLLMs) when applied to video understanding tasks. It covers two main aspects: benchmarks for evaluation and mitigation methods.

---

## üìö Survey of Hallucination

A collection of survey papers focusing on hallucination in large language models (LLMs) and multimodal large models (MLLMs), primarily in text and image contexts, serving as background for understanding video hallucination.

1. [Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2502.08826) (arXiv 2025.02)
2. [A Survey on Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2402.00253) (arXiv 2024.02)
3. [Paper Title 3](link)
4. [Paper Title 4](link)
5. [Paper Title 5](link)

---

## üìä Video Hallucination Benchmarks

A list of datasets and evaluation frameworks designed to assess hallucination in video-grounded MLLMs.

1. [EventHallusion: Diagnosing Event Hallucinations in Video LLMs](https://arxiv.org/abs/2409.16597) (arXiv 2024.09)
2. [ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large Multimodal Models](https://arxiv.org/abs/2411.10867) (arXiv 2024.11)
3. [Paper Title 3](link)
4. [Paper Title 4](link)
5. [Paper Title 5](link)

---

## üõ†Ô∏è Video Hallucination Mitigation Methods

A collection of methods proposed to reduce or control hallucination in MLLMs for video understanding, including model design, input processing, decoding strategies, and training objectives.

1. [Can Hallucination Correction Improve Video-Language Alignment?](https://arxiv.org/abs/2502.15079) (arXiv 2025.02)
2. [Hallucination of Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2404.18930) (arXiv 2024.04)
3. [Paper Title 3](link)
4. [Paper Title 4](link)
5. [Paper Title 5](link)

---

## üìå Notes

- Contributions via pull requests or issues are welcome.
- For each paper, consider adding publication venue (arXiv / Conference / Journal), date, and a short description.
- If available, please include links to benchmark code or project pages.
