# Video-Hallucination-of-MLLM

This repository collects research papers related to hallucination in Multimodal Large Language Models (MLLMs) when applied to video understanding tasks. It covers two main aspects: benchmarks for evaluation and mitigation methods.

---

## üìö Survey of Hallucination

A collection of survey papers focusing on hallucination in large language models (LLMs) and multimodal large models (MLLMs), primarily in text and image contexts, serving as background for understanding video hallucination.

1. [Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2502.08826) (arXiv 2025.02)
2. [A Survey on Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2402.00253) (arXiv 2024.02)

---

## üìä Video Hallucination Benchmarks

A list of datasets and evaluation frameworks designed to assess hallucination in video-grounded MLLMs.

1. [VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations for Synthetic Videos](https://arxiv.org/abs/2505.01481) (arXiv 2025.05)
2. [Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation](https://arxiv.org/abs/2503.19622) (arXiv 2025.03)
3. [VIDHALLUC: Evaluating Temporal Hallucinations in Multimodal Large Language Models for Video Understanding](https://www.arxiv.org/pdf/2412.03735) (arXiv 2024.12)
4. [ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large Multimodal Models](https://arxiv.org/abs/2411.10867) (arXiv 2024.11)
5. [THE CURSE OF MULTI-MODALITIES: EVALUATING HALLUCINATIONS OF LARGE MULTIMODAL MODELS ACROSS LANGUAGE, VISUAL, AND AUDIO](https://arxiv.org/abs/2410.12787) (arXiv 2024.10)
6. [EventHallusion: Diagnosing Event Hallucinations in Video LLMs](https://arxiv.org/abs/2409.16597) (arXiv 2024.09)
7. [VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in Large Video-Language Models](https://arxiv.org/abs/2406.16338) (arXiv 2024.06)

---

## üõ†Ô∏è Video Hallucination Mitigation Methods

A collection of methods proposed to reduce or control hallucination in MLLMs for video understanding, including model design, input processing, decoding strategies, and training objectives.

1. [VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations for Synthetic Videos](https://arxiv.org/abs/2505.01481) (arXiv 2025.05)
2. [ResNetVLLM-2: Addressing ResNetVLLM‚Äôs Multi-Modal Hallucinations](https://arxiv.org/abs/2504.14429) (arXiv 2025.04)
3. [PaMi-VDPO Mitigating Video Hallucinations by Prompt-Aware](https://arxiv.org/abs/2504.05810) (arXiv 2025.04)
4. [MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through Disentangled Spatial-Temporal Representations](https://arxiv.org/abs/2503.15871) (arXiv 2025.03)
5. [Can Hallucination Correction Improve Video-Language Alignment?](https://arxiv.org/abs/2502.15079) (arXiv 2025.02)
6. [VideoRoPE: What Makes for Good Video Rotary Position Embedding?](https://arxiv.org/abs/2502.05173) (arXiv 2025.02)
7. [Video Token Sparsification for Efficient Multimodal LLMs in Autonomous Driving](https://arxiv.org/abs/2409.11182) (arXiv 2024.09)

---

## üìå Notes

- Contributions via pull requests or issues are welcome.
- For each paper, consider adding publication venue (arXiv / Conference / Journal), date, and a short description.
- If available, please include links to benchmark code or project pages.
